<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="A collection of my open-source and commercial projects I've worked on."><title>Alexey Borsky | Projects</title><link rel=canonical href=https://volotat.github.io/projects/><link rel=stylesheet href=/scss/style.min.833d6eed45de56f48306bf57268d5b8cdfc8a60e8e7bdc99810464fcd033f7c6.css><meta property='og:title' content="Projects"><meta property='og:description' content="A collection of my open-source and commercial projects I've worked on."><meta property='og:url' content='https://volotat.github.io/projects/'><meta property='og:site_name' content='Alexey Borsky'><meta property='og:type' content='website'><meta property='og:updated_time' content=' 2025-08-21T00:00:00+00:00 '><meta name=twitter:title content="Projects"><meta name=twitter:description content="A collection of my open-source and commercial projects I've worked on."><link rel=alternate type=application/rss+xml href=https://volotat.github.io/projects/index.xml><link rel="shortcut icon" href=/favicon.png></head><body><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_e5db16934e59d865.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Alexey Borsky</a></h1><h2 class=site-description>Self taught programmer and ML engineer. Active open-source contributor. Mostly interested in procedural generation and generative AI.</h2></div></header><ol class=menu-social><li><a href=https://github.com/volotat target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://x.com/volotat target=_blank title=X rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-x"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4l11.733 16H20L8.267 4z"/><path d="M4 20l6.768-6.768m2.46-2.46L20 4"/></svg></a></li><li><a href=https://www.youtube.com/@volotat target=_blank title=YouTube rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-youtube"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M2 8a4 4 0 014-4h12a4 4 0 014 4v8a4 4 0 01-4 4H6a4 4 0 01-4-4V8z"/><path d="M10 9l5 3-5 3z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li class=current><a href=/projects/><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-file-code"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 3v4a1 1 0 001 1h4"/><path d="M17 21H7a2 2 0 01-2-2V5a2 2 0 012-2h7l5 5v11a2 2 0 01-2 2z"/><path d="M10 13l-1 2 1 2"/><path d="M14 13l1 2-1 2"/></svg>
<span>Projects</span></a></li><li><a href=/archives/><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-notebook"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M6 4h11a2 2 0 012 2v12a2 2 0 01-2 2H6a1 1 0 01-1-1V5a1 1 0 011-1m3 0v18"/><path d="M13 8h2"/><path d="M13 12h2"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><form action=/search/ class="search-form widget"><p><label>Search</label>
<input name=keyword required placeholder="Type something...">
<button title=Search>
<svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></button></p></form><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-infinity" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M9.828 9.172a4 4 0 100 5.656A10 10 0 0012 12a10 10 0 012.172-2.828 4 4 0 110 5.656A10 10 0 0112 12 10 10 0 009.828 9.172"/></svg></div><h2 class="widget-title section-title">Archives</h2><div class=widget-archive--list><div class=archives-year><a href=/archives/#2025><span class=year>2025</span>
<span class=count>4</span></a></div><div class=archives-year><a href=/archives/#2024><span class=year>2024</span>
<span class=count>2</span></a></div><div class=archives-year><a href=/archives/#2023><span class=year>2023</span>
<span class=count>2</span></a></div><div class=archives-year><a href=/archives/#2022><span class=year>2022</span>
<span class=count>4</span></a></div><div class=archives-year><a href=/archives/#2021><span class=year>2021</span>
<span class=count>3</span></a></div><div class=archives-year><a href=/archives/#2018><span class=year>More</span></a></div></div></section><section class="widget tagCloud"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Categories</h2><div class=tagCloud-tags><a href=/categories/projects/ class=font_size_13>Projects
</a><a href=/categories/ideas/ class=font_size_5>Ideas
</a><a href=/categories/anagnorisis/ class=font_size_4>Anagnorisis
</a><a href=/categories/highlights/ class=font_size_2>Highlights</a></div></section><section class="widget tagCloud"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg></div><h2 class="widget-title section-title">Tags</h2><div class=tagCloud-tags><a href=/tags/machine-learning/>Machine Learning
</a><a href=/tags/open-source/>Open Source
</a><a href=/tags/experiments/>Experiments
</a><a href=/tags/ai/>AI
</a><a href=/tags/data-privacy/>Data Privacy
</a><a href=/tags/personalization/>Personalization
</a><a href=/tags/information-management/>Information Management
</a><a href=/tags/recommendation-system/>Recommendation System
</a><a href=/tags/research/>Research
</a><a href=/tags/arc-agi/>ARC-AGI</a></div></section></aside><main class="main full-width"><section class=article-list><article class=has-image><div class=article-image><a href=/projects/2023-10-08-anagnorisis/><img src=/projects/2023-10-08-anagnorisis/anagnorisis-screenshot%20from%202026-01-02.png loading=lazy alt="Featured image of Anagnorisis"></a></div><div class=article-details><header class=article-category><a href=/categories/projects/ style=background-color:#2a9d8f;color:#fff>Projects
</a><a href=/categories/anagnorisis/ style=background-color:#521b77;color:#fff>Anagnorisis</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/projects/2023-10-08-anagnorisis/>Anagnorisis</a></h2></div><section class=article-content style=color:var(--card-text-color-main)><p>Completely local data-management platform with built in trainable recommendation engine.</p><p>The core idea is to create a self-hosted local-first media platform where you can rate your data, and the system trains a personal model to understand your preferences. This model then sorts your data based on your predicted interest, creating a personalized filter for any type of media you might have — images, music, videos, articles, and more.</p><ul><li><strong>Local First:</strong> All data always stays on your device only. All models are trained and inferenced locally.</li><li><strong>AI Powered:</strong> Uses advanced embeddings (CLAP, SigLIP, Jina) to understand, search and filter your content and estimate preferences.</li><li><strong>FullStack:</strong> Built with Flask, Bulma, Transformers, and PyTorch. Uses simple Docker setup for easy deployment.</li><li><strong>Open Source:</strong> AGPL-3.0 license. Contributions, feedback and support are always welcome!</li></ul><p><strong>Status:</strong> Active Development.</p><p><a class=link href=https://github.com/volotat/Anagnorisis target=_blank rel=noopener>View on GitHub</a></p></section><footer class=article-time><div class=article-tags style=margin-bottom:10px><a href=/tags/machine-learning/ class=tag>Machine Learning
</a><a href=/tags/recommendation-system/ class=tag>Recommendation System
</a><a href=/tags/open-source/ class=tag>Open Source
</a><a href=/tags/personalization/ class=tag>Personalization
</a><a href=/tags/data-privacy/ class=tag>Data Privacy</a></div></footer></div></article><article class=has-image><div class=article-image><a href=/projects/2022-08-27-vector-based-language/><img src=/projects/2022-08-27-vector-based-language/1_lgXj1-BGYkDVqLytrz9D9A.png loading=lazy alt="Featured image of Vector Based Language"></a></div><div class=article-details><header class=article-category><a href=/categories/projects/ style=background-color:#2a9d8f;color:#fff>Projects
</a><a href=/categories/highlights/ style=background-color:#3577ce;color:#fff>Highlights</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/projects/2022-08-27-vector-based-language/>Vector Based Language</a></h2></div><section class=article-content style=color:var(--card-text-color-main)><p>Research project exploring the possibility of creating a continuous, visual language that hint at the possibility of direct understanding of the embedding spaces produced by ML models.</p><p>Unlike traditional discrete languages, this system uses machine learning to generate unique visual representations (images) for any given text embedding. The goal is to create a language where concepts can blend into each other continuously, mirroring how neural networks process information.</p><p>Words and sentences are represented as points in a continuous vector space, allowing for smooth transitions between concepts. Experiments show that humans can learn to interpret these generated visual embeddings with increasing accuracy over time. The visual language is designed to be perfectly reconstructible back into the original text embeddings by a decoder network crating a bridge between human cognition and the &ldquo;black box&rdquo; mechanized interpretation of the data.</p><p><strong>Status:</strong> Completed Experiment</p><p><a class=link href=/p/can-humans-speak-the-language-of-the-machines/>Read the Article</a> | <a class=link href=https://github.com/volotat/Vector-Based-Language target=_blank rel=noopener>View on GitHub</a></p></section><footer class=article-time><div class=article-tags style=margin-bottom:10px><a href=/tags/machine-learning/ class=tag>Machine Learning
</a><a href=/tags/nlp/ class=tag>NLP
</a><a href=/tags/research/ class=tag>Research
</a><a href=/tags/open-source/ class=tag>Open Source
</a><a href=/tags/transhumanism/ class=tag>Transhumanism</a></div></footer></div></article><article class=has-image><div class=article-image><a href=/projects/2025-05-15-4d-volumetric-retina-simulation/><img src=/projects/2025-05-15-4d-volumetric-retina-simulation/4D_eye_preview.png loading=lazy alt="Featured image of 4D Volumetric Retina Simulation"></a></div><div class=article-details><header class=article-category><a href=/categories/projects/ style=background-color:#2a9d8f;color:#fff>Projects</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/projects/2025-05-15-4d-volumetric-retina-simulation/>4D Volumetric Retina Simulation</a></h2></div><section class=article-content style=color:var(--card-text-color-main)><p>A physics-based 4D path tracing simulation visualizing how a four-dimensional being might perceive the world through a 3D volumetric retina.</p><p>Current visualizations of 4D space often rely on wireframe projections or simple 3D cross-sections. This project takes a more biologically plausible approach: analogous to how we 3D beings perceive our world via 2D retinas, a 4D creature would likely possess a 3D (volumetric) retina.</p><p>This simulation implements a custom 4D path tracing engine (using Python and Taichi for GPU acceleration) to model light interactions within a hyper-scene containing a rotating tesseract. It simulates image formation by casting 4D rays onto a defined 3D retinal volume.</p><p>The simulation features physically-based rendering that models light bounces, shadows, and perspective in four spatial dimensions. Simulates a 3D sensor array rather than a flat plane. Implements a Gaussian fall-off for retinal sensitivity, mimicking foveal vision where the center of the 3D gaze is most acute. To make this comprehensible to human eyes, the 3D retinal image is composited from multiple depth slices, additively blended to represent the density of information a 4D being would process simultaneously.</p><p><strong>Status:</strong> Completed Experiment</p><p><a class=link href=https://github.com/volotat/4DRender target=_blank rel=noopener>View on GitHub</a> | <a class=link href=https://www.youtube.com/shorts/T697zlLvvHw target=_blank rel=noopener>Video Showcase</a></p></section><footer class=article-time><div class=article-tags style=margin-bottom:10px><a href=/tags/4d/ class=tag>4D
</a><a href=/tags/open-source/ class=tag>Open Source
</a><a href=/tags/research/ class=tag>Research
</a><a href=/tags/experiments/ class=tag>Experiments</a></div></footer></div></article><article class=has-image><div class=article-image><a href=/projects/2023-03-17-sd-cn-animation/><img src=/projects/2023-03-17-sd-cn-animation/ui_preview.png loading=lazy alt="Featured image of SD-CN-Animation"></a></div><div class=article-details><header class=article-category><a href=/categories/projects/ style=background-color:#2a9d8f;color:#fff>Projects</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/projects/2023-03-17-sd-cn-animation/>SD-CN-Animation</a></h2></div><section class=article-content style=color:var(--card-text-color-main)><p>This project was developed as an extension for the <a class=link href=https://github.com/AUTOMATIC1111/stable-diffusion-webui target=_blank rel=noopener>Automatic1111 web UI</a> to automate video stylization and enable text-to-video generation using <a class=link href=https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5 target=_blank rel=noopener>Stable Diffusion 1.5</a> backbones. At the time of development, generated videos often suffered from severe flickering and temporal inconsistency. This framework addressed those issues by integrating the <a class=link href=https://github.com/princeton-vl/RAFT target=_blank rel=noopener>RAFT</a> optical flow estimation algorithm. By calculating the motion flow between frames, the system could warp the previously generated frame to match the motion of the next one, creating a stable base for the diffusion model. This process, combined with occlusion masks, ensured that only new parts of the scene were generated while maintaining the consistency of existing objects.</p><p>The tool supported both video-to-video stylization and experimental text-to-video generation. In video-to-video mode, users could apply <a class=link href=https://huggingface.co/lllyasviel/ControlNet target=_blank rel=noopener>ControlNet</a> to guide the structure of the output, allowing for stable transformations like turning a real-life video into a watercolor painting or digital art while preserving the original motion. The text-to-video mode employed a custom &ldquo;FloweR&rdquo; method to hallucinate optical flow from static noise, attempting to generate continuous motion from text prompts alone.</p><p>Development on this project was eventually discontinued as the field rapidly advanced. The emergence of modern, end-to-end text-to-video models provided much more coherent and faithful results than could be achieved by hacking image-based diffusion models, rendering this approach largely obsolete for general use cases.</p><p><strong>Status:</strong> Not Maintained</p><p><a class=link href=https://github.com/volotat/SD-CN-Animation target=_blank rel=noopener>View on GitHub</a></p></section><footer class=article-time><div class=article-tags style=margin-bottom:10px><a href=/tags/stable-diffusion/ class=tag>Stable Diffusion
</a><a href=/tags/ai/ class=tag>AI
</a><a href=/tags/video-generation/ class=tag>Video Generation
</a><a href=/tags/open-source/ class=tag>Open Source</a></div></footer></div></article><article class=has-image><div class=article-image><a href=/projects/2021-12-04-generative-art-synthesizer/><img src=/projects/2021-12-04-generative-art-synthesizer/gas_preview.png loading=lazy alt="Featured image of Generative Art Synthesizer"></a></div><div class=article-details><header class=article-category><a href=/categories/projects/ style=background-color:#2a9d8f;color:#fff>Projects</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/projects/2021-12-04-generative-art-synthesizer/>Generative Art Synthesizer</a></h2></div><section class=article-content style=color:var(--card-text-color-main)><p>A Python program that generates Python programs that generate generative art.</p><p>Most generative art relies on stochastic processes where the initial seed and specific parameters are often lost, making exact reproduction difficult. GAS takes a different approach: instead of storing just the output or the parameters, it generates a fully deterministic, standalone Python script for each artwork. This ensures complete reproducibility—if you have the script, you have the art.</p><p>The core mechanism involves initializing a tensor with coordinate data and then applying a random sequence of mathematical transformations (like <code>transit</code>, <code>sin</code>, <code>magnitude</code>, <code>shift</code>) to its channels. These operations are restricted to the [-1, 1] range to ensure stability. The final result is a composition of these channels converted into color space.</p><ul><li><strong>Self-Contained Art:</strong> Each generated piece is a runnable Python script with zero external dependencies beyond standard scientific libraries (numpy, PIL).</li><li><strong>Deterministic:</strong> The generated scripts contain no random elements; running the same script always produces the exact same image.</li><li><strong>Method-Based generation:</strong> Uses a palette of composable mathematical functions (<code>sin</code>, <code>prod</code>, <code>soft_min</code>, etc.) to &ldquo;sculpt&rdquo; the image in a high-dimensional channel space.</li><li><strong>Aesthetic Scoring:</strong> Includes a simple scoring model to estimate the visual quality of generated outputs.</li></ul><p><strong>Status:</strong> Completed Experiment</p><p><a class=link href=https://github.com/volotat/GAS target=_blank rel=noopener>View on GitHub</a></p></section><footer class=article-time><div class=article-tags style=margin-bottom:10px><a href=/tags/generative-art/ class=tag>Generative Art
</a><a href=/tags/open-source/ class=tag>Open Source
</a><a href=/tags/procedural-generation/ class=tag>Procedural Generation
</a><a href=/tags/meta-programming/ class=tag>Meta-Programming
</a><a href=/tags/experiments/ class=tag>Experiments</a></div></footer></div></article></section><nav class=pagination role=navigation aria-label=pagination><a class="page-link disabled" aria-label="Previous page" aria-disabled=true><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-chevron-left"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M15 6l-6 6 6 6"/></svg>
</a><a class="page-link current" aria-label="Page 1" aria-current=page>1
</a><a class=page-link href=/projects/page/2/ aria-label="Page 2">2
</a><a class=page-link href=/projects/page/2/ aria-label="Next page"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-chevron-right"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 6l6 6-6 6"/></svg></a></nav><footer class=site-footer><section class=copyright>&copy;
2017 -
2026 Alexey Borsky</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.33.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>